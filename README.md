# Motion-detection-to-motor-spinning

This artifact includes two separate parts: motion detection module (from here out: MDM) and wearable touch simulation (from here out: WTS). We achieved the motion detection on Raspberry pi with a python program revised from an open-source script written by brainflakes. An nRF24 module was connected to the Raspberry pi so that it can send the motion detection signal to the simulation part wirelessly. In the touch simulation part, three servo motors along with an PCA9685 16-Channel Servo Driver were installed on the wearable facial mask to simulate the touch. Ultralight clay was adopted as the material to build the touching surface, which is light and soft for skin contact. The other nRF24 module was connected to the Arduino to receive the motion detection signal, so that the movement of the plants can remotely trigger the wearable touch simulation on the human body.
